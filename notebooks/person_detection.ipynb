{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model = torch.hub.load('pytorch/vision:v0.6.0', 'deeplabv3_resnet101', pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "# img = Image.open(\"/home/thyde/avatar-stuff/frames/s01e01/frame2990.jpg\")\n",
    "\n",
    "\n",
    "# def img_transform(img):\n",
    "#     def to_rgb(pil):\n",
    "#         return pil.convert('RGB')\n",
    "#     image_transform = transforms.Compose([\n",
    "#         transforms.Resize(500),\n",
    "#         transforms.CenterCrop(500),\n",
    "#         to_rgb,\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize(\n",
    "#             mean=[0.485, 0.456, 0.406],\n",
    "#             std=[0.229, 0.224, 0.225]),\n",
    "#     ])\n",
    "#     return image_transform(img)\n",
    "\n",
    "# input_tensor = img_transform(img)\n",
    "# input_batch = input_tensor.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if torch.cuda.is_available():\n",
    "#     input_batch = input_batch.to('cuda')\n",
    "#     model.to('cuda')\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     output = model(input_batch)['out'][0]\n",
    "# output_predictions = output.argmax(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_segmaps(input_batch, model, reduce_max=False, to_numpy=False):\n",
    "#     out = model(input_batch)\n",
    "#     segmaps = out['out']\n",
    "#     if reduce_max:\n",
    "#         segmaps = segmaps.argmax(1)\n",
    "#     if to_numpy:\n",
    "#         segmaps = segmaps.data.numpy()\n",
    "#     return segmaps\n",
    "\n",
    "# segmap = get_segmaps(input_batch, model, reduce_max=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0=background, 1=aeroplane, 2=bicycle, 3=bird, 4=boat, 5=bottle\n",
    "# 6=bus, 7=car, 8=cat, 9=chair, 10=cow\n",
    "# 11=dining table, 12=dog, 13=horse, 14=motorbike, 15=person\n",
    "# 16=potted plant, 17=sheep, 18=sofa, 19=train, 20=tv/monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/home/thyde/avatar-stuff/frames/person_frames.pickle','rb') as f:\n",
    "    person_frames = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_frames[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "img_paths = os.listdir('/home/thyde/avatar-stuff/frames/s01e09')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize(600),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "class ImageFolderWithPaths(torchvision.datasets.ImageFolder):\n",
    "    \"\"\"Custom dataset that includes image file paths. Extends\n",
    "    torchvision.datasets.ImageFolder\n",
    "    \"\"\"\n",
    "\n",
    "    # override the __getitem__ method. this is the method dataloader calls\n",
    "    def __getitem__(self, index):\n",
    "        # this is what ImageFolder normally returns\n",
    "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        # the image file path\n",
    "        path = self.imgs[index][0]\n",
    "        # make a new tuple that includes original and the path\n",
    "        tuple_with_path = (original_tuple + (path,))\n",
    "        return tuple_with_path\n",
    "\n",
    "\n",
    "dataset = ImageFolderWithPaths('/home/thyde/avatar-stuff/frames/s01e09', transform=image_transform)\n",
    "dataloader = DataLoader(dataset, \n",
    "                       shuffle=True, \n",
    "                       batch_size=12,\n",
    "                      num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import frogress\n",
    "# person_frames = list()\n",
    "model.to('cuda')\n",
    "for batch in frogress.bar(dataloader, steps=len(dataloader)):\n",
    "    input_batch = batch[0]\n",
    "    input_batch = input_batch.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        segmaps = model(input_batch)['out'].argmax(1)\n",
    "#     import pdb;pdb.set_trace()\n",
    "    for idx, segmap in enumerate(segmaps):\n",
    "        if 15 in segmap:\n",
    "            if batch[2][idx] not in person_frames:\n",
    "                person_frames.append(batch[2][idx])\n",
    "\n",
    "with open('/home/thyde/avatar-stuff/frames/person_frames.pickle', 'wb') as fp:\n",
    "    pickle.dump(person_frames, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(person_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv3.6.8",
   "language": "python",
   "name": "venv3.6.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
